{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender Systems using PySpark\n",
    "=============\n",
    "Recommender Systems have derived great importance in understanding user behavior. It has found its extensive application in e-commerce, user modelling,etc. PySpark is one of the best tools for implementing recommender systems for date of size  upto 5GB. This is because of extremely fast computations in pyspark through its in-memory processing capabilities.\n",
    "> Never update the PATH env variable in \\/etc\\/environment directly the way you modify other variables. Rather add the expanded path in the exisiting PATH env variable declaration as bellow\n",
    "\n",
    "What is Map-Reduce Operation?\n",
    "-----\n",
    "\n",
    "\n",
    "![Map Reduce word count Diagram](MapReduceWordCountOverview1.png \"Word Count - A map-reduce example\")\n",
    "\n",
    "What is HDFS File System?\n",
    "-----\n",
    "\n",
    "How does a program execute on a cluster?\n",
    "-----\n",
    "\n",
    "Basics of pyspark\n",
    "======\n",
    "\n",
    "Recommender Systems\n",
    "======\n",
    "\n",
    "Recommender in Pyspark\n",
    "======\n",
    "\n",
    "Import Data\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using ALS algorithm and hence we have imported it first. The next step is to read the date from its source into RDD. This is done via spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "raw_data = sc.textFile('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us observe the content of movies.csv befor we start getting recommendations for a new user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId,title,genres\r\n",
      "\n",
      "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\r\n",
      "\n",
      "2,Jumanji (1995),Adventure|Children|Fantasy\r\n",
      "\n",
      "3,Grumpier Old Men (1995),Comedy|Romance\r\n",
      "\n",
      "4,Waiting to Exhale (1995),Comedy|Drama|Romance\r\n",
      "\n",
      "5,Father of the Bride Part II (1995),Comedy\r\n",
      "\n",
      "6,Heat (1995),Action|Crime|Thriller\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,lines in enumerate(open('ml-latest-small/movies.csv','r').readlines()):\n",
    "    print lines\n",
    "    if(idx>5):break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
